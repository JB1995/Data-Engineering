{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9869f6ae-711f-4aba-ade4-1574a391874c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Write a PySpark code to perform:\n",
    "- Check for duplicates and drop them if found in primary keys (1-10).\n",
    "- Filter out rows with null or empty primary keys.\n",
    "- Replace nulls in non-primary keys with 0.\n",
    "- Reject rows where all values in columns 11 to 20 are null (non-primary keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e9ff98-cd13-4e35-bbc0-9b4de7dbf445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, types as T, functions as F\n",
    "from pyspark.sql.window import Window as W\n",
    "spark = SparkSession.builder.appName('spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "177205bd-7e5e-4e3c-904a-a26cb0e33e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "(\"A1\",\"B1\",\"C1\",\"D1\",\"E1\",\"F1\",\"G1\",\"H1\",\"I1\",\"J1\",10,20,30,40,50,60,70,80,90,100),\n",
    "(\"A1\",\"B1\",\"C1\",\"D1\",\"E1\",\"F1\",\"G1\",\"H1\",\"I1\",\"J1\",1,2,3,4,5,6,7,8,9,10),\n",
    "(None,\"B2\",\"C2\",\"D2\",\"E2\",\"F2\",\"G2\",\"H2\",\"I2\",\"J2\",5,5,5,5,5,5,5,5,5,5),\n",
    "(\"\",\"B3\",\"C3\",\"D3\",\"E3\",\"F3\",\"G3\",\"H3\",\"I3\",\"J3\",1,1,1,1,1,1,1,1,1,1),\n",
    "(\"A4\",\"B4\",\"C4\",\"D4\",\"E4\",\"F4\",\"G4\",\"H4\",\"I4\",\"J4\",None,None,None,None,None,None,None,None,None,None),\n",
    "(\"A5\",\"B5\",\"C5\",\"D5\",\"E5\",\"F5\",\"G5\",\"H5\",\"I5\",\"J5\",None,2,None,4,None,6,None,8,None,10),\n",
    "(\"A6\",\"B6\",\"C6\",\"D6\",\"E6\",\"F6\",\"G6\",\"H6\",\"I6\",\"J6\",11,22,33,44,55,66,77,88,99,111)\n",
    "]\n",
    "columns = [f'col{i}' for i in range(1,21)]\n",
    "df=spark.createDataFrame(data, schema=columns)\n",
    "df=df.withColumn('id', F.row_number().over(W.orderBy(F.lit('1'))))\n",
    "# df=df.withColumn('id', F.monotonically_increasing_id())\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ee8aae-a073-4418-9bf6-5ebe55204ec7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pk_columns = [f'col{i}' for i in range(1,11)]\n",
    "npk_columns = [f'col{i}' for i in range(11,21)]\n",
    "print(pk_columns, npk_columns, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cf17cc1-fce5-4716-aa28-b6ad4c00ede6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###1. Check for duplicates and drop them if found in primary keys(1-10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "797ed997-2b9f-4ea2-b295-77db39cee4ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=df.dropDuplicates(pk_columns)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a13bdb45-15de-42cb-8594-eb287c316169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###2. Filter out rows with null or empty primary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7717824a-95c4-4fa7-a35e-bb1cf4b21301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pk_condition=None\n",
    "for cols in pk_columns:\n",
    "    condition = (F.col(cols).isNotNull()) & (F.trim(cols)!='')\n",
    "    pk_condition=condition if pk_condition is None else pk_condition & condition\n",
    "df=df.filter(pk_condition)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "483b3988-a949-46ee-9f07-20b5ea3a0cd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###4. Reject rows where all values in columns 11 to 20 are null (non-primary keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9597db2-dd7c-45c0-8a4e-a6822c8d8e31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "npk_condition=None\n",
    "for cols in npk_columns:\n",
    "    condition=(F.col(cols).isNull())\n",
    "    npk_condition=condition if npk_condition is None else npk_condition & condition\n",
    "df=df.filter(~npk_condition)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd495219-8b47-40c5-89bd-f9ea22e5531e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###3. Replace nulls in non-primary keys with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82927158-d2b7-4fcf-b5a0-a60e176ea933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=df.fillna(0, subset=npk_columns)\n",
    "df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Q3.Data cleaning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
